# LLM Provider Configuration
# Options: ollama, hf (huggingface), gemini
LLM_PROVIDER=ollama

# Ollama Configuration (for local LLM)
OLLAMA_MODEL=llama3.2:3b
OLLAMA_HOST=http://127.0.0.1:11434

# Hugging Face Configuration
# Get your token from: https://huggingface.co/settings/tokens
HUGGINGFACE_TOKEN=your_huggingface_token_here
HF_MODEL=meta-llama/Meta-Llama-3-8B-Instruct

# Google Gemini Configuration  
# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-flash-8b